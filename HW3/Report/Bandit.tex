%!TEX root = ./HW3.tex

\section{Bandit Problem}
A 10 step and 100 step version of the Bandit Problem were tested.  For both tests, XXXX total steps were run.  The solution quality for the 100 step agent is superior to the 10 step problem.

\subsection{Problem Description}
The goal for the bandit problem is to maximize the expected return given a set of slot machines that give a reward.  In this test, the rewards have a gaussian distrubution and is different for each slot machine.  The number of steps is the number of steps allowed before the situation is reset.  For the Bandit Problem, the initial state is with the accumulated reward as zero.

\subsection{Results}
An action value learning agent is used in both cases.  Figure \ref{} shows the expected values as estimated by the learning for both situations compared to the actual distribution of the learners.

-- Actino Value learning tables. \\
-- Show something about progress? like reward as a function of number of steps learned over.


\input{BanditComparison10.tex}
\input{BanditComparison100.tex}